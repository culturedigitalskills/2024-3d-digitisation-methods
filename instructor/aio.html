<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Digitisation Methods for Material Culture: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="manifest" href="../site.webmanifest">
<link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg">
</div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Digitisation Methods for Material Culture
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="search button" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Digitisation Methods for Material Culture
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
<input class="form-control me-2 searchbox" type="search" placeholder="Search" aria-label="Search"><button class="btn btn-outline-success tablet-search-button" type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="search button"></i>
        </button>
      </fieldset>
</form>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Digitisation Methods for Material Culture
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->
      
            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="material-culture.html">1. Material Culture</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="types-of-media.html">2. Types of Media</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="methods.html">3. 3D Digitisation methods</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="resources-and-further-reading.html">4. Resources and Further Reading</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width resources">
<a href="../instructor/aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">
            
            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-material-culture"><p>Content from <a href="material-culture.html">Material Culture</a></p>
<hr>
<p>Last updated on 2024-02-03 |
        
        <a href="https://github.com/culturedigitalskills/2024-3d-digitisation-methods/edit/main/episodes/material-culture.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<section id="definition"><h2 class="section-heading">Definition<a class="anchor" aria-label="anchor" href="#definition"></a>
</h2>
<hr class="half-width">
<p><strong>Material culture</strong> constitutes an interdisciplinary
domain looking into the connections between individuals and the objects
they produce. This field spans the creation, history, preservation, and
interpretation of objects, involving the examination of tangible
artefacts and their significance. It draws on a spectrum of disciplines,
including art history, archaeology, anthropology, ethnography, history,
and heritage studies.</p>
<figure><img src="../fig/AdobeStock_402902014.jpeg" alt="pixels" class="figure mx-auto d-block"><figcaption>日本の伝統芸能、神楽、広島神楽、新舞、魅力、文化の継承、kagura、八幡、悪魔王、鬼
© by Beautiful Japan 90 under Education License from Adobe Stock</figcaption></figure><p>Encompassing a diverse array of tangible objects shaped or altered by
human hands, material culture ranges from buildings and architectural
elements to textiles, books, decorative objects, instruments, and
everyday items. Material culture explores the meaning of artefacts their
use, lifespan and associations within various social, historical and
political contexts.</p>
<div class="section level3">
<h3 id="intersection-with-cultural-heritage">Intersection with Cultural Heritage<a class="anchor" aria-label="anchor" href="#intersection-with-cultural-heritage"></a>
</h3>
<p>Material culture is a component of cultural heritage, contributing to
the tangible aspects of a group’s legacy.</p>
<p>While not all material culture is part of cultural heritage, the
intersection lies in the fact that cultural heritage includes both
tangible (material culture) and intangible elements such as knowledge,
poems, myths, dance or language. Together, they form the cultural
practices and expressions of a particular group.</p>
</div>
<div class="section level3">
<h3 id="material-culture-study">Material culture study<a class="anchor" aria-label="anchor" href="#material-culture-study"></a>
</h3>
<p>Examining material culture holds significance as it offers valuable
insights into the history, beliefs, and practices of communities and
societies. This exploration aids in understanding how individuals shape
objects and are influenced by them in several contexts, impacting social
relations, work dynamics, and cultural identity. The study of material
culture plays a crucial role in heritage preservation and
interpretation, stimulates creativity, and acts as a bridge between
academic knowledge and public understanding.</p>
<p>Key issues in studying material culture include:</p>
<ul>
<li>the challenge of interpreting objects’ meanings</li>
<li>understanding the contexts in which they were produced and used</li>
<li>recognising the dynamic nature of their significance over time</li>
<li>looking at the preservation of objects, including the practices
involved in it</li>
<li>ethical considerations around the objects and their lives</li>
<li>potential biases introduced by cultural, political, or economic
factors.</li>
</ul>
<p>The contribution of material culture studies is also multifaceted.
Its impact is evident in domains such as material citizenship
(acknowledging the politics of things); stewardship (caring for
culturally significant items); insightful scholarship on the history of
object-making and usage; creativity in material culture; and fostering
common ground between the public and academia.</p>
</div>
</section><section id="approaches-towards-material-culture"><h2 class="section-heading">Approaches towards material culture<a class="anchor" aria-label="anchor" href="#approaches-towards-material-culture"></a>
</h2>
<hr class="half-width">
<p>The two main approaches towards objects and material culture,
identified by Bernard Herman (1992) are the “object-centred” approach,
which focuses on the physical attributes of the object itself, and the
“object-driven” approach, which emphasises understanding how objects
relate to the cultures and peoples that create and use them. These
approaches involve detailed description and contextualisation,
respectively.</p>
<div class="section level4">
<h4 id="object-centred">Object-centred<a class="anchor" aria-label="anchor" href="#object-centred"></a>
</h4>
<p><strong>Focus:</strong></p>
<ul>
<li>
<strong>Object attributes</strong>: This approach centres on the
physical attributes and characteristics of the object itself.</li>
<li>
<strong>Description</strong>: It involves a detailed and focused
description of the object, including its materials, size, colours,
texture, weight, shape, design, style, decorative status, and
provenance.</li>
<li>
<strong>Creation process</strong>: It explores how the object was
made, with a focus on the materials and techniques employed.</li>
<li>
<strong>Purpose</strong>: It seeks to understand the object in terms
of its intended purpose and function.</li>
</ul>
<p><strong>Significance:</strong></p>
<ul>
<li>
<strong>Materiality</strong>: Emphasises the material aspects of the
object.</li>
<li>
<strong>Classification</strong>: Aids in categorising objects,
identifying artistic styles, and attributing works to specific artists
or periods.</li>
</ul>
</div>
<div class="section level4">
<h4 id="object-driven">Object-driven<a class="anchor" aria-label="anchor" href="#object-driven"></a>
</h4>
<p><strong>Focus</strong>:</p>
<ul>
<li>
<strong>Context and meaning</strong>: This approach shifts the focus
towards understanding how objects relate to the cultures and people that
create and use them.</li>
<li>
<strong>Contextualisation</strong>: Investigates the broader context
in which objects are located and used.</li>
<li>
<strong>Function and symbolism</strong>: Explores the changing
meanings of objects within specific social and cultural practices.</li>
<li>
<strong>Cultural significance</strong>: Considers how objects
reflect the values and beliefs of the societies that produced them.</li>
</ul>
<p><strong>Significance</strong>:</p>
<ul>
<li>
<strong>Dynamic nature</strong>: Recognises the dynamic nature of
the meanings of objects over time and space.</li>
<li>
<strong>Cultural insights</strong>: Provides insights into societal
values, beliefs, and practices.</li>
<li>
<strong>Agency</strong>: Acknowledges that objects can have an
active role in creating meaning rather than being passive.</li>
</ul>
<p>In summary, the object-centred approach focuses on the
<strong>materiality</strong> and <strong>specific attributes</strong> of
objects, while the object-driven approach emphasises the broader
<strong>cultural, social, and historical contexts</strong> in which
these objects exist and gain <strong>meaning</strong>.</p>
<p>Please note that object-centred and object-driven approaches are not
necessarily mutually exclusive, and they can overlap. Object-centred
approaches start with a close examination of the object and work
outwards, while object-driven approaches start with the broader context
and then delve into a greater understanding of the object. Combining
both approaches allows for a more comprehensive understanding of
material culture, considering both the intrinsic qualities of objects
and their dynamic relationships with cultural and social contexts.</p>
</div>
</section><section id="object-biographies"><h2 class="section-heading">Object biographies<a class="anchor" aria-label="anchor" href="#object-biographies"></a>
</h2>
<hr class="half-width">
<p>Object biographies refer to the conceptualisation of objects having
life cycles, from conception and creation to use, appreciation, and
eventual termination or afterlife. Like people, objects go through
stages, acquiring new identities, meanings, and travels. Object
biographies highlight the dynamic and evolving nature of objects within
cultural and historical contexts.</p>
<figure><img src="../fig/AdobeStock_715909042.jpeg" alt="pots" class="figure mx-auto d-block"><figcaption>Artefacts arranged in a display case at an
archaeological museum, showcasing the fruits of excavation © by Julia
(Generated with AI) under Education License from Adobe Stock</figcaption></figure><p>Some key aspects of the objects’ biographies can be found below.</p>
<div class="section level3">
<h3 id="conception-and-creation">Conception and creation:<a class="anchor" aria-label="anchor" href="#conception-and-creation"></a>
</h3>
<ul>
<li>Like birth: Objects are conceived, designed, and created, akin to
the birth or initiation phase in a human life.</li>
<li>Intention and purpose: The process involves the intentions of the
creators, the purpose for which the object is made, and the cultural or
social context of its creation.</li>
</ul>
</div>
<div class="section level3">
<h3 id="use-consumption-and-appreciation">Use, consumption, and appreciation:<a class="anchor" aria-label="anchor" href="#use-consumption-and-appreciation"></a>
</h3>
<ul>
<li>Like life and growth: Objects, like living beings, have a period of
use and consumption. They are employed for various purposes,
appreciated, and contribute to human activities and experiences.</li>
<li>Utility and meaning: Objects serve utilitarian functions while also
accumulating meanings and associations based on how they are used and
valued by individuals or communities.</li>
</ul>
</div>
<div class="section level3">
<h3 id="disintegration-or-afterlife">Disintegration, or afterlife:<a class="anchor" aria-label="anchor" href="#disintegration-or-afterlife"></a>
</h3>
<ul>
<li>Like death or transformation: At the end of their use or relevance,
objects may undergo processes of dissolution, disintegration, or
transformation.</li>
<li>Afterlife in museums: Some objects may find a form of afterlife in
museums, where they are preserved, displayed, and continue to contribute
to cultural understanding.</li>
</ul>
</div>
<div class="section level3">
<h3 id="travels-and-identity">Travels and identity:<a class="anchor" aria-label="anchor" href="#travels-and-identity"></a>
</h3>
<ul>
<li>Like journeys in life: Objects, like people, can go on journeys.
Through travels, they acquire new identities and meanings in different
cultural, geographical, or historical contexts.</li>
<li>Cultural significance: The travels of objects may contribute to
their cultural significance and influence their interpretations.</li>
</ul>
</div>
<div class="section level3">
<h3 id="forces-shaping-destiny">Forces shaping destiny:<a class="anchor" aria-label="anchor" href="#forces-shaping-destiny"></a>
</h3>
<ul>
<li>External influences: Throughout their existence, objects are
subjected to wider forces in the world that shape their destinies. This
includes cultural, social, economic, and political influences.</li>
<li>Adaptation: Objects, like living organisms, may adapt to changing
circumstances and acquire new roles or meanings.</li>
</ul>
</div>
<div class="section level3">
<h3 id="object-biographies-and-interpretation">Object biographies and interpretation:<a class="anchor" aria-label="anchor" href="#object-biographies-and-interpretation"></a>
</h3>
<ul>
<li>Understanding change: Object biographies help in understanding how
the meanings and uses of objects change over time and in different
cultural contexts.</li>
<li>Cultural dynamics: They highlight the dynamic nature of the
relationships between people and objects, as well as the cultural
dynamics that influence these relationships.</li>
</ul>
<p>Essentially, object biographies offer a narrative framework for
exploring the life trajectories of objects, providing a dynamic
perspective on their existence within human societies. This approach
acknowledges the agency of objects and their roles in shaping and
reflecting cultural practices, beliefs, and identities.</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<p>Look at the different aspects of objects’ biographies and think about
the objects that you study and document within the context of your
research. What are the key aspects that you focus on and what is
something that you would like to further expand on?</p>
</div>
</div>
</div>
</div>
</section><section id="capturing-and-sharing-material-culture"><h2 class="section-heading">Capturing and sharing material culture<a class="anchor" aria-label="anchor" href="#capturing-and-sharing-material-culture"></a>
</h2>
<hr class="half-width">
<p>Digital documentation enhances our understanding of material
knowledge by creating accessible records of objects. Deploying
technologies such as digital imaging, 3D scanning, and databases,
researchers and practitioners can capture and disseminate details about
artefacts, facilitating the study and preservation of material culture.
Moreover, digital documentation enables public access and engagement,
advancing discussions on diverse interpretations, even those involving
contested narratives within cultural heritage.</p>
<figure><img src="../fig/scottish_boat_workshop_sketchfab.png" alt="boat 3D image" class="figure mx-auto d-block"><figcaption>Screenshot of Scottish Boatbuilding School: Workshop
© by the Scottish Maritime Museum, under CC0 Public Domain from <a href="https://sketchfab.com/ScottishMaritimeMuseum" class="external-link">Sketchfab</a></figcaption></figure><p>Media, including textual recordings, imagery, 3D scans and visual
reconstructions of the past, contribute to communicating material
culture by visually representing objects and conveying knowledge.
However, we should always keep in mind that such media essentially
constitute subjective means of representation, introducing potential
distortions and bias through a process of agency. When looking at media
as vehicles of representation, there should be careful consideration of
how such media portray objects, events, communities, societies and their
identity within specific contexts over time.</p>
</section><section id="resources-and-further-reading"><h2 class="section-heading">Resources and further reading<a class="anchor" aria-label="anchor" href="#resources-and-further-reading"></a>
</h2>
<hr class="half-width">
<p>Augustat, C. (2020). A Play in the Field of Words: From Material
Culture to/and Cultural Heritage. INDIANA - Estudios Antropológicos
sobre América Latina y el Caribe. Vol. 37 Núm. 2 (2020). Retrieved from:
<a href="https://doi.org/10.18441/ind.v37i2.237-245" class="external-link uri">https://doi.org/10.18441/ind.v37i2.237-245</a></p>
<p>De Cunzo, L. A., &amp; Roeber, C. D. (Eds.). (2022). The Cambridge
Handbook of Material Culture Studies. Cambridge: Cambridge University
Press.</p>
<p>Herman, B. L. (1992). The Stolen House. Charlottesville and London:
The University Press of Virginia.</p>
<p>Papadopoulos, C. (2020). Course: Unit 1: An introduction to 3D
heritage. dariahTeach: Open Educational Resources for the Digital Arts
and Humanities. Retrieved from: <a href="https://teach.dariah.eu/course/view.php?id=55&amp;section=1" class="external-link uri">https://teach.dariah.eu/course/view.php?id=55&amp;section=1</a></p>
<p>The Open University. (2014). An introduction to material culture. The
open university. Retrieved from: <a href="https://www.open.edu/openlearn/history-the-arts/visual-art/an-introduction-material-culture/content-section-0?active-tab=content-tab" class="external-link uri">https://www.open.edu/openlearn/history-the-arts/visual-art/an-introduction-material-culture/content-section-0?active-tab=content-tab</a></p>
<p>Tilley, C. (2012). Handbook of material culture. Sage
Publications.</p>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></section><section id="aio-types-of-media"><p>Content from <a href="types-of-media.html">Types of Media</a></p>
<hr>
<p>Last updated on 2024-02-03 |
        
        <a href="https://github.com/culturedigitalskills/2024-3d-digitisation-methods/edit/main/episodes/types-of-media.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 60 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<p><strong>Multidimensional</strong> media is a term which covers
various types of non-textual data. It is often used to refer to
representational and derivative media created through digitisation
processes or synthetic images produced via software. These processes
often result in multi-part, multi-format and, often, large project files
which describe the creation process.</p>
<p>We refer to media as <strong>multidimensional</strong>. This is
because data experts structure information according to the
<strong>dimensions</strong> used to store the data in the computer
system.</p>
<p>For example, the <strong>name</strong> of one of your friends can be
stored in a data type with <strong>1-dimension</strong>:</p>
<pre><code>John Smith</code></pre>
<p>Meanwhile, a table which stores the name of all your friends and
their addresses will use a data type similar to a spreadsheet table.</p>
<pre><code>| Name            | Address         |
|-----------------|-----------------|
| John Smith      | 34 Street Rd    |
| Marion Lopes    | 105 Babel St    |
</code></pre>
<p>The latter uses <strong>2-dimensions</strong> as both rows and
columns are used to organised the data.</p>
<section id="digital-images"><h2 class="section-heading">Digital Images<a class="anchor" aria-label="anchor" href="#digital-images"></a>
</h2>
<hr class="half-width">
<p>Data in digital images is organised similar to tables, as
<em>pixels</em> or <em>picture elements</em>, which are the smallest
element of an image, are organised across <strong>2-dimensions</strong>.
We usually refer to these dimensions as the <em>x</em>, <em>y</em>
axis.</p>
<figure><img src="../fig/pixel-example.png" alt="pixels" class="figure mx-auto d-block"><figcaption>Example of pixels. © ed g2s from Wikimedia
Commons</figcaption></figure><p>The <strong>image resolution</strong> usually refers to how many
<em>pixels</em> an image has, either as a total or its width. This is
why <em>resolution</em> is usually given in <em>2-dimensions</em>, for
example an image with a resolution of <em>800 × 600 pixels</em> will
have <em>800 pixels</em> across the x-axis (its width), and <em>600
pixels</em> across the y-axis (its height). The image will contain
<em>480,000 pixels</em> in total.</p>
<figure><img src="../fig/resolution_test.jpg" alt="3 pictures of a car, from a high resolution (to the left) to a low resolution (to the right)" class="figure mx-auto d-block"><figcaption>3 pictures of a car, from a high resolution (to the
left) to a low resolution (to the right) © Ruizo~commonswiki from
Wikimedia</figcaption></figure><p>Meanwhile, the <strong>PPI</strong> or <strong>DPI</strong>
(<strong>Pixels per Inch</strong> or <strong>Dots Per Inch</strong>)
attributes of images refer to their pixel density. That is how many
pixels there are in 1 inch (2.54 cm) in the display in which the image
is <em>rendered</em> or in the printed image.</p>
<figure><img src="../fig/AdobeStock_136018032.jpeg" alt="DPI example" class="figure mx-auto d-block"><figcaption>Resolution screen pixel density © brovarky from
AdbobeStock</figcaption></figure><p>Example of digital images include digital photographs generated by a
camera sensor (e.g. on a smart phone), or synthetic images created on
directly on the computer (e.g. painting tools or generated by Artificial
Intelligence software).</p>
<p><img src="../fig/AdobeStock_552189310.jpeg" alt="photographs" class="figure"><img src="../fig/AdobeStock_635196929.jpeg" alt="generated" class="figure"></p>
<p>Given the wide-availability of camera sensors, including on smart
phones and digital cameras, digital images are the widest available
multidimensional media.</p>
<div class="section level3">
<h3 id="image-platforms">Image Platforms<a class="anchor" aria-label="anchor" href="#image-platforms"></a>
</h3>
<p>Collections of images are found across many websites, and popular
search engines now support image-based search which allows to search
digital-images across websites giving an input image. See examples:</p>
<ul>
<li><a href="https://pixabay.com/" class="external-link">Pixabay</a></li>
<li><a href="https://stock.adobe.com/" class="external-link">Adobe Stock</a></li>
<li><a href="https://www.shutterstock.com/" class="external-link">Shutterstock</a></li>
<li><a href="https://www.flickr.com/" class="external-link">Flickr</a></li>
</ul>
<div id="challenge-search-for-images" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="challenge-search-for-images" class="callout-inner">
<h3 class="callout-title">Challenge: Search for images<a class="anchor" aria-label="anchor" href="#challenge-search-for-images"></a>
</h3>
<div class="callout-content">
<p>Save the image below and navigate in your browser to <a href="https://www.google.com/" class="external-link">https://www.google.com/</a>. Using the
camera image on the search bar, search for the image.</p>
<figure><img src="../fig/Europeana.eu-794-ark__12148_bpt6k9798997w-c5e37f95e1fa32b494a103e2f3d5baf2.jpeg" alt="Peter Rabit magazine" class="figure mx-auto d-block"><figcaption>The Tale of Peter Rabbit / Beatrix Potter - 1920 -
National Library of France, France - No Copyright - Other Known Legal
Restrictions. <a href="https://www.europeana.eu/item/794/ark__12148_bpt6k9798997w" class="external-link uri">https://www.europeana.eu/item/794/ark__12148_bpt6k9798997w</a></figcaption></figure>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="image-formats">Image Formats<a class="anchor" aria-label="anchor" href="#image-formats"></a>
</h3>
<p>Finally, images are commonly stored using formats such such as:</p>
<ul>
<li>
<em>JPEG</em>, short for Joint Photographic Experts Group, and
<em>PNG</em>, short for <em>Portable Network Graphics</em> formats
compress pixel information making the files size smaller.</li>
<li>
<em>TIFF</em>, short for <em>Tag Image File Format</em>, stores
non-compressed information, making the file size larger.</li>
</ul>
<p>Digital photography will make use of other formats, such as
<em>DNG</em> or <em>RAW</em> to store raw image information. Other
software store image projects in proprietary formats, meaning files can
only be open by these.</p>
</div>
</section><section id="digital-video"><h2 class="section-heading">Digital Video<a class="anchor" aria-label="anchor" href="#digital-video"></a>
</h2>
<hr class="half-width">
<p>Digital video could be considered a <strong>2-dimensional</strong>
or, even a <strong>3-dimensional</strong>, type of media.</p>
<p>This is because a video contains many images or
<strong>frames</strong>, which are stored in
<strong>2-dimensions</strong> as described above, and rendered
sequentially.</p>
<p><img src="../fig/AdobeStock_598901894.png" alt="frames in video" class="figure"><img src="../fig/AdobeStock_603342595.jpeg" alt="frames in video frog" class="figure"></p>
<p>Videos also have a <strong>Resolution</strong> which is related to
the images. The resolution will be the same for all the frames in a
video file. For instance, a 4K video is usually made of frames which are
X x Y in resolution.</p>
<p>The rate at which frames are displayed is usually referred to as
<strong>Frames Per Second</strong> or <strong>FPS</strong>. For
reference, TV and movies are usually displayed at 24 FPS.</p>
<div class="section level3">
<h3 id="video-platforms">Video Platforms<a class="anchor" aria-label="anchor" href="#video-platforms"></a>
</h3>
<p>Video is also a popular type of content, as there are many other
platforms on the web which allow users to easily share their media. See
examples:</p>
<ul>
<li><a href="https://www.youtube.com" class="external-link">YouTube</a></li>
<li><a href="https://vimeo.com/" class="external-link">Vimeo</a></li>
<li><a href="https://commons.wikimedia.org/wiki/Category:Videos" class="external-link">Wikimedia</a></li>
</ul>
<p>Note that while images can be downloaded by web browsers, it is not
always possible to download video from these websites. Many times, video
is only made available through a media player.</p>
</div>
<div class="section level3">
<h3 id="video-formats">Video Formats<a class="anchor" aria-label="anchor" href="#video-formats"></a>
</h3>
<p>There are many formats to store video and audio, including those
supported by webpages:</p>
<ul>
<li>MP4 (MPEG-4) is a common <em>container format</em> which can play in
almost all devices and over the web.</li>
<li>WebM and OGG are open video formats.</li>
</ul>
<p>There are many others <a href="https://en.wikipedia.org/wiki/Video_file_format" class="external-link">formats</a>.</p>
<p>Note that videos with higher resolution and FPS will be larger and
hence, challenging to send via email or download over the web.</p>
</div>
</section><section id="d-images-or-models"><h2 class="section-heading">3D Images or Models<a class="anchor" aria-label="anchor" href="#d-images-or-models"></a>
</h2>
<hr class="half-width">
<p>A <strong>3D model</strong> is a 3-dimensional type of media. It
describes 3D shapes along with other information related to their
appearance, e.g. colour information.</p>
<p>To understand how <strong>3D models</strong> are described and
displayed in the computer, we need to understand two concepts:
<strong>vector</strong> and <strong>raster</strong> data.</p>
<p>In this lesson, we won’t cover how <strong>3D models</strong> are
created.</p>
<p>There are resources here to learn more about processes:</p>
<ul>
<li><a href="https://carare.gitbook.io/share-3d-guidelines/3d-process/context" class="external-link">CARARE
Introduction to the 3D workflow</a></li>
<li><a href="https://sketchfab.com/blogs/community/how-to-set-up-a-successful-photogrammetry-project" class="external-link">Photogrammetry</a></li>
<li><a href="https://digital-strategy.ec.europa.eu/en/library/basic-principles-and-tips-3d-digitisation-cultural-heritage" class="external-link">Basic
principles and tips for 3D digitisation of cultural heritage</a></li>
</ul>
<div class="section level3">
<h3 id="vector-data">Vector Data<a class="anchor" aria-label="anchor" href="#vector-data"></a>
</h3>
<p>Regardless of the process, the output of these processes, in most
cases will produce a <strong>3D model</strong> file which contains
<strong>vector</strong> data.</p>
<!--
:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: instructor

This exercise requires having access to blank paper and a square-grid paper.

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: challenge 

## Challenge 1: Drawing a 3D-cube

In a piece of blank paper, draw a 3-dimensional cube or box of dimensions:

height = 1 

width = 1  

depth = 1

::::::::::::::::::::::::::::::::::::: solution 

To describe a 3D cube, the file will contain
data describing the 6 squares using 
point coordinates (e.g. (1,0,0)).

![](fig/cube.png){alt='cube vector format'width=60%}


In the example below, a squareis described
using 4 points or *vertices*: (0,0,0), (1,0,0), (1,1,0) and (0,1,0).


![](fig/square.svg){alt='square vector format'width=60%}

:::::::::::::::::::::::::::::::::


::::::::::::::::::::::::::::::::::::: solution 


:::::::::::::::::::::::::::::::::

## Challenge 2: Draw it again

Now, using a square-grid paper draw again your cube or box using the 
same dimensions. In this exercise you must decide whether to fill or
not the squares of the grid to draw your 3-dimensional box.

:::::::::::::::::::::::: solution 

You have just experienced the concept of **Rasterisation**. 

This challenge illustrates the decision made by the computer
on what information to display on the screen. It must decide
whether a pixel should be drawn or not to represent the 
information of the 3D-cube you drawn.


::::::::::::::::::::::::::::::::::::::::::::::::

-->
<p>These data include:</p>
<ul>
<li>Points or vertices described in a 3D space.</li>
<li>Information on how the points are connected to form shapes such as
triangles, which is known as the topology or connectivity of the 3D
model.</li>
<li>Colour or texture (image) information which describe its
appearance.</li>
</ul>
</div>
<div class="section level3">
<h3 id="raster-data">Raster Data<a class="anchor" aria-label="anchor" href="#raster-data"></a>
</h3>
<p><strong>Rasterisation</strong> is the process to go from a
<strong>vector</strong> description into a <strong>raster</strong>
image.</p>
<p>The <strong>raster image</strong> is the pixel-based representation
of the vector description.</p>
<figure><img src="../fig/Top-left_triangle_rasterization_rule.gif" style="width:60.0%" alt="square raster format" class="figure mx-auto d-block"><figcaption>Rasterization process © <a href="https://commons.wikimedia.org/wiki/File:Top-left_triangle_rasterization_rule.gif" class="external-link">Drummyfish</a>
under CC0</figcaption></figure><!--
![](fig/square_raster.svg){alt='square raster format' width=60%}
--><p><strong>3D models</strong> are <em>rendered</em> as raster images on
the screen, smartphone or any other display device (e.g. a Virtual
Reality headset). The computer will have to <em>compute</em> this raster
image in real-time, which is why <strong>3D models</strong> which
contain many vertices can be slow to <em>render</em>.</p>
</div>
<div class="section level3">
<h3 id="examples-of-3d-models">Examples of 3D models<a class="anchor" aria-label="anchor" href="#examples-of-3d-models"></a>
</h3>
<p>We tend to use <strong>3D model</strong> to refer to many types of
spatial data.</p>
<p>For example, see below an example of a 3D model of an architectural
space.</p>
<!-- Points in space acquired by a sensor device such
as a 3D scanner, or 
- Points calculated by a photogrammetry process, which calculates
spatial data from images of the same object.-->
<iframe name="Bamberg, Kaisersaal, 4x8k" src="https://kompakkt.de/viewer/index.html?entity=61f7bce9605228325f63190d&amp;mode=open" allowfullscreen loading="lazy" width="100%" height="500px">
</iframe>
<p><a href="https://kompakkt.de/entity/64181f0a07603d5bf4087497" class="external-link">3D
model from Kompakkt © Jan Lutteroth, Corpus der brocken Deckenmalerei,
Institut für Kunstgeschichte</a></p>
<p>This is a 3D model of an individual object.</p>
<iframe src="https://visual.ariadne-infrastructure.eu/3d/reperto_05" allowfullscreen loading="lazy" width="100%" height="500px">
</iframe>
<p><a href="https://visual.ariadne-infrastructure.eu/3d/reperto_05" class="external-link">©
Trozzella (Messapian pottery) from VisualMedia Service</a></p>
<p>In many cases, the 3D data can be mostly points in 3D space as shown
below.</p>
<iframe src="https://potree.org/potree/examples/viewer.html" width="100%" height="500px" frameborder="0">
</iframe>
<p><a href="https://potree.org/potree/examples/viewer.html" class="external-link">Point cloud
rendered in Potree which is a viewer for large point cloud / LIDAR data
sets © Markus Schütz</a></p>
<p>Spatial data can also be recorded with an additional parameter -
<strong>time</strong>.</p>
<p>For instance, motion capture devices will generate vector data which
changes many times within a second. We call this measure sampling rate
per second.</p>
<iframe title="Motion Capture : Antonio d'Angelo / Effigy" frameborder="0" allowfullscreen mozallowfullscreen="true" width="100%" height="500px" webkitallowfullscreen="true" allow="autoplay; fullscreen; 
xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share src="https://sketchfab.com/models/02238db7b53348cb863d3f6eafb413bf/embed">
</iframe>
<p><a href="https://sketchfab.com/3d-models/motion-capture-antonio-dangelo-effigy-02238db7b53348cb863d3f6eafb413bf" class="external-link">Motion
Capture Dataset © Antonio d’Angelo / Effigy, 3D animated model from
Sketchfab</a></p>
</div>
<div class="section level3">
<h3 id="d-model-platforms">3D Model Platforms<a class="anchor" aria-label="anchor" href="#d-model-platforms"></a>
</h3>
<p>Popular format platforms include:</p>
<ul>
<li><a href="https://sketchfab.com/" class="external-link">Sketchfab</a></li>
<li><a href="https://www.tinkercad.com/" class="external-link">Tinkercad</a></li>
<li><a href="https://www.morphosource.org/" class="external-link">MorphoSource</a></li>
<li><a href="https://kompakkt.de/home?locale=en" class="external-link">Kompakkt</a></li>
<li><a href="https://3d.si.edu/" class="external-link">Smithsonian 3D</a></li>
<li><a href="https://openheritage3d.org/" class="external-link">Open Heritage 3D</a></li>
<li><a href="https://visual.ariadne-infrastructure.eu/" class="external-link">Visual Media
Service</a></li>
</ul>
<p>As with video, the <em>viewers</em> for <strong>3D models</strong>
normally allow to visualise and interact with the information. But these
viewers do not always allow to download the model that is viewed.</p>
</div>
<div class="section level3">
<h3 id="d-model-formats">3D Model Formats<a class="anchor" aria-label="anchor" href="#d-model-formats"></a>
</h3>
<p>There are many file formats for <strong>3D images</strong> or
<strong>models</strong> including:</p>
<ul>
<li>GLTF (JSON/ASCII) or GLB (binary) is the standard Graphics Library
Transmission Format which is commonly used for <strong>3D
models</strong> on the web.</li>
<li>OBJ, USD and PLY are popular format for 3D data which support
additional information, such as textures or colour.</li>
<li>STL is a popular format in 3D printing and rapid prototyping.</li>
</ul>
<p>Other proprietary formats such as FBX and 3DS will contain vector
information on scenes.</p>
<p>The number of points/vertices or triangles are used to determine the
resolution of the 3D model. Note that, as with images and video,
<strong>3D models</strong> that have a larger number of vertices, for
example, over 100,000 will have a larger size. This has an impact on how
long it takes to download, load or <em>render</em> this content.</p>
</div>
</section><section id="gathering-multidimensional-files"><h2 class="section-heading">Gathering Multidimensional Files<a class="anchor" aria-label="anchor" href="#gathering-multidimensional-files"></a>
</h2>
<hr class="half-width">
<p>Great variety of multidimensional content is available through the
various platforms for research, education, entertainment and
storytelling among other applications.</p>
<p>Some aggregation websites offer access to a variety of visual
content, including:</p>
<ul>
<li><a href="https://www.europeana.eu/en" class="external-link">Europeana Platform</a></li>
<li><a href="https://commons.wikimedia.org/wiki/Category:Images" class="external-link">Wikimedia
Commons</a></li>
</ul>
<p>Other discipline specific or museum sites include:</p>
<ul>
<li><a href="https://journalofdigitalhistory.org/" class="external-link">Journal of Digital
History Journal</a></li>
<li><a href="https://collections.brightonmuseums.org.uk/" class="external-link">Brighton and
Hove Museums</a></li>
<li><a href="https://www.vam.ac.uk/collections?type=featured" class="external-link">Victoria
and Albert Museum</a></li>
<li><a href="https://collection.sciencemuseumgroup.org.uk/" class="external-link">Science
Group Museum</a></li>
</ul>
<p>Some general advice when looking for content for your projects
includes:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Download the multimedia file</strong> where possible and
store locally or on the repository where you are curating the data
set.</li>
<li>Use the <strong>maximum resolution possible</strong>. It is always
possible to reduce the number of pixels, but not to increase them.</li>
<li>
<strong>Record basic metadata</strong> about the file, including the
reference and copyright to the image.</li>
</ol>
<p>If you are doing additional research look at data models, such as the
<a href="https://www.dublincore.org/specifications/dublin-core/cross-domain-attribute/" class="external-link">Dublin-CORE
cross domain set</a>, which contains useful information to store,
including:</p>
<ul>
<li>Title</li>
<li>Subject</li>
<li>Description</li>
<li>Date</li>
<li>Resource Type</li>
<li>Format</li>
<li>Resource Identifier</li>
<li>Language</li>
<li>Rights Management</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Remember to use a suitable file name to keep easy track of the media
and its provenance. If the file it is too large, it is possible to
resize and save again in medium and low quality.</li>
</ol>
<p>For example:</p>
<pre><code>		WebsiteFromWhereFileWasDownloaded_ResourceID_[high|medium|low].[format] </code></pre>
<p>This will become:</p>
<pre><code><span>    <span class="va">Flick_photo1234_high.png</span></span>
<span>    <span class="va">Flick_photo1234_medium.png</span></span>
<span>    <span class="va">Flick_photo1234_low.png</span></span></code></pre>
<div class="section level3">
<h3 id="controlled-vocabularies">Controlled vocabularies<a class="anchor" aria-label="anchor" href="#controlled-vocabularies"></a>
</h3>
<p>To facilitate the quality of documentation, findability, access and
long-term preservation of data, controlled vocabularies can be also used
to help with adding the above-mentioned and further data. Essentially,
controlled vocabularies, with their standardised terms and language,
describe artefacts, objects, or concepts within a specific domain and
help organise and communicate information in databases and information
systems.</p>
<p>Some of the most well-known and used vocabularies in the cultural
heritage domain are:</p>
<ul>
<li><a href="https://www.getty.edu/research/tools/vocabularies/aat/" class="external-link">The
Getty Art &amp; Architecture Thesaurus (AAT)</a></li>
<li><a href="https://www.getty.edu/research/tools/vocabularies/tgn/index.html" class="external-link">The
Getty Thesaurus of Geographic Names (TGN)</a></li>
<li><a href="https://www.getty.edu/research/tools/vocabularies/ulan/index.html" class="external-link">The
Union List of Artist Names (ULAN)</a></li>
<li><a href="https://www.getty.edu/research/tools/vocabularies/cona/index.html" class="external-link">The
Cultural Objects Name Authority (CONA) (in progress)</a></li>
<li><a href="https://www.loc.gov/aba/publications/FreeLCSH/freelcsh.html" class="external-link">The
Library of Congress Subject Headings (LCSH)</a></li>
<li><a href="https://perio.do/en/" class="external-link">PeriodO - A gazetteer of periods for
linking and visualizing data</a></li>
</ul>
<p>More vocabularies in the heritage domain exist and serve different
purposes. Some further examples from Historic England, Historic
Environment Scotland and the Royal Commission on Ancient &amp;
Historical Monuments of Wales (RCAHMW) can be found <a href="https://www.heritagedata.org/blog/vocabularies-provided/" class="external-link">here</a>.</p>
<p>Tools to map vocabularies also exist, such as the <a href="https://heritagedata.org/vocabularyMatchingTool/" class="external-link">Vocabulary
Matching Tool</a> by the University of South Wales and the <a href="https://vmt.ariadne.d4science.org/vmt/vmt-app.html" class="external-link">Vocabulary
Matching Tool</a> by the EU Horizon 2020-funded AriadnePlus project.</p>
<p>The organisation of terms within controlled vocabularies typically
adheres to a taxonomy. Taxonomies categorise or classify vocabularies
usually in a hierarchical way. An interesting taxonomy in the field of
Digital Humanities is the <a href="https://vocabs.dariah.eu/tadirah/en/" class="external-link">TaDiRAH Taxonomy of Digital
Research Activities in the Humanities</a>.</p>
<p>More information about controlled vocabularies can be found in the
following resources:</p>
<ul>
<li><p>Europeana (2021). Webinar: Using Vocabularies and Linked data:
#Connecting Archaeology. Retrieved from: <a href="https://pro.europeana.eu/event/using-vocabularies-and-linked-data-connecting-archaeology" class="external-link">https://pro.europeana.eu/event/using-vocabularies-and-linked-data-connecting-archaeology</a></p></li>
<li><p>Getty Center. Vocabularies for Cultural Heritage Objects.
Retrieved from: <a href="https://www.getty.edu/research/publications/electronic_publications/intro_controlled_vocab/cultural_objects.pdf" class="external-link">https://www.getty.edu/research/publications/electronic_publications/intro_controlled_vocab/cultural_objects.pdf</a></p></li>
<li><p>Harpring, P. (2023). Getty Vocabularies and Linked Oped Data
(LOD). Retrieved from: <a href="https://www.getty.edu/research/tools/vocabularies/Linked_Data_Getty_Vocabularies.pdf" class="external-link">https://www.getty.edu/research/tools/vocabularies/Linked_Data_Getty_Vocabularies.pdf</a></p></li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li><p>Digital Images are organized using pixels, the smallest elements
of an image, which are arranged across 2 dimensions (x and y
axis).</p></li>
<li><p>Image resolution refers to the number of pixels, and it is
usually given in 2 dimensions (e.g., 800 × 600 pixels).</p></li>
<li><p>Digital Video is a 2-dimensional or even 3-dimensional type of
media.</p></li>
<li><p>Videos consist of multiple frames stored in 2 dimensions (like
images).</p></li>
<li><p>Videos also have a resolution and frame rate (Frames Per
Second).</p></li>
<li><p>3D Images or Models are files containing vector data describing
spatial information.</p></li>
<li><p>Rasterization is the process of converting vector graphics into
raster images.</p></li>
<li><p>Various aspects need to be considered when collecting, storing,
and managing multimedia files effectively.</p></li>
<li><p>Recording metadata and using appropriate file naming conventions
is important.</p></li>
</ul>
</div>
</div>
</div>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</section></section><section id="aio-methods"><p>Content from <a href="methods.html">3D Digitisation methods</a></p>
<hr>
<p>Last updated on 2024-02-03 |
        
        <a href="https://github.com/culturedigitalskills/2024-3d-digitisation-methods/edit/main/episodes/methods.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 60 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<section id="context"><h2 class="section-heading">Context<a class="anchor" aria-label="anchor" href="#context"></a>
</h2>
<hr class="half-width">
<p>3D digitisation has a rich history dating back to the 1960s,
originating from the pioneering work at MIT in computer-aided design.
However, over the past few decades, it has progressively evolved into a
widespread practice, driven by improved accessibility and affordability
of hardware and software systems used for acquiring, processing, and
visualising 3D data.</p>
<figure><img src="../fig/cultlab.jpeg" alt="digitisation rig." class="figure mx-auto d-block"><figcaption>CultLab3D: Automated Scanning Technology for 3D
Digitisation © by Project Leader: M.Sc. Inform. Pedro Santos, Head of
Competence Center for Cultural Heritage Digitization at Fraunhofer
Institute for Computer Graphics Research IGD - European Heritage Awards
Archive, Austria under CC0 Public Domain from <a href="https://www.europeana.eu/item/945/EHA_EUROPEANHERITAGEAWARDSARCHIVEEU_000000001396" class="external-link">Europeana</a></figcaption></figure><p>Like with many technologies, the heritage domain has served as a
valuable testing ground for exploring different equipment, workflows,
and methods to visualise and interact with digital heritage assets.</p>
<p>The primary advantage of 3D digitised assets lies in the inherent
nature of their multidimensional data, which can be easily manipulated
for detailed study or to highlight specific attributes, exchanged via
the web, and experienced by the public through a diverse range of online
and offline applications.</p>
<p>Over the past few years, major institutions like the <a href="https://3d.si.edu/" class="external-link">Smithsonian</a>, the <a href="https://sketchfab.com/britishmuseum" class="external-link">British Museum</a>, the <a href="https://learning.sciencemuseumgroup.org.uk/format/3d/" class="external-link">Science
Museum</a> have promoted 3D digitisation initiatives for their
collections and have also made collections of 3D objects accessible
online.</p>
<p>Given the gradual democratisation of 3D technologies, it can be
argued that 3D digitisation has become crucial for various aspects of
cultural heritage management.</p>
<p>It enables conservation and restoration efforts, facilitates the
study and exchange of knowledge among researchers and communities,
reconstructs damaged or lost assets and sites, and provides access to
remote or inaccessible objects and locations.</p>
<p>Additionally, it allows individuals, including those with
impairments, to experience artefacts, monuments, and sites.</p>
<figure><img src="../fig/image002.png" alt="" class="figure mx-auto d-block"><figcaption>Time Cost Scope triangle icon. Clipart image isolated
on white background, © by dzm1try under Education License from Adobe
stock</figcaption></figure><p>To choose the right method to digitise in 3D a collection of
artefacts, a monument or site, several decisions need to be taken
concerning the:</p>
<ul>
<li>Aim of the project</li>
<li>Scope of the project (e.g., collection to digitise and
type/size/condition/location of assets)</li>
<li>Audience of the project</li>
<li>Cost of digitisation</li>
<li>Resources (hardware, software, staff time)</li>
<li>Knowledge and skills</li>
<li>Purpose of digitisation</li>
</ul>
<p>All these, as well as issues around data sovereignty, Intellectual
Property Rights (IPR) and ethics will define the quality, reach and
potential impact of the project.</p>
</section><section id="planning-for-3d-digitisation"><h2 class="section-heading">Planning for 3D digitisation<a class="anchor" aria-label="anchor" href="#planning-for-3d-digitisation"></a>
</h2>
<hr class="half-width">
<p>When setting up a digitisation project, it is imperative to have a
careful plan in mind about the purpose, the resources and the processes
of the project.</p>
<p>A data management plan is also necessary to as part of such
preparation. The National Heritage Lottery Fund (2023) has recently
produced a <a href="https://www.heritagefund.org.uk/sites/default/files/media/attachments/Digitisation%20project%20planner%20and%20handbook.pdf" class="external-link">Digitisation
Project Planner</a> to help with such preparation.</p>
<p>Currently, there are no internationally recognised standards for
planning, organising, setting up, and implementing a 3D data acquisition
project. Furthermore, there is no widely accepted standard for
specifying the level of detail and accuracy required for 3D
digitisation.</p>
<p>Additionally, there are no standard guidelines regarding the quantity
and quality of data for acquisition and delivery. Consequently, there is
a clear need for standardisation to ensure the sustainability and
long-term preservation of 3D data, including facilitating access, and
interaction with data.</p>
<div id="challenge-digitisation-planner" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="challenge-digitisation-planner" class="callout-inner">
<h3 class="callout-title">Challenge: Digitisation Planner<a class="anchor" aria-label="anchor" href="#challenge-digitisation-planner"></a>
</h3>
<div class="callout-content">
<p>Access and download the <a href="https://www.heritagefund.org.uk/sites/default/files/media/attachments/Digitisation%20project%20planner%20and%20handbook.pdf" class="external-link">Digitisation
Planner</a> from the National Heritage Lottery Fund website.</p>
<p>Go through the sections of the planner (sheet 1 and 2) and try to
respond to the proposed questions.</p>
<p>Are there any sections or questions where you need to put more effort
into responding to within the context of your project?</p>
<p>Try to articulate and write down some responses to these
questions.</p>
</div>
</div>
</div>
</section><section id="methods"><h2 class="section-heading">Methods<a class="anchor" aria-label="anchor" href="#methods"></a>
</h2>
<hr class="half-width">
<p>There are many methods to capture or construct 3D data and there is
always research and efforts to combine methods and experiment with new
acquisition types and combinations of data. Here we present the most
widespread methods in the field of 3D digitisation.</p>
<div class="section level3">
<h3 id="photogrammetry">Photogrammetry<a class="anchor" aria-label="anchor" href="#photogrammetry"></a>
</h3>
<p>Photogrammetry is the ‘art, science, and technology of obtaining
reliable information about physical objects and the environment through
processes of recording, measuring and interpreting photographic images’
(American Society for Photogrammetry and Remote Sensing).</p>
<p>Photogrammetry is one of the most popular methods to acquire
information about the shape and appearance of cultural heritage assets,
as it is cost-effective and essentially involves capturing 2D images
with a camera and then using appropriate software to construct a 3D
model.</p>
<p>This happens sequentially as the photogrammetric software will first
detect features on the images, then proceed with feature matching and
lastly, it will reconstruct the 3D asset with or without colour.</p>
<p>DSLR cameras, digital compact cameras and even mobile phones can be
used for photogrammetry, but the result of such acquisition will largely
depend on the conditions and quality of the acquired images.</p>
<p>Photogrammetry can be used for different heritage objects, ranging
from small movable artefacts to large immovable assets or sites. Aerial
photogrammetry is used to acquire images from the air using an aircraft
or drone (UAV - Unmanned Aerial Vehicle) and combining them with
georeferencing data. Terrestrial photogrammetry is used to acquire
images from the ground or near the ground with cameras. Close-range
photogrammetry is a branch of terrestrial photogrammetry and refers to
the acquisition of photographs from a shorter distance with regards to
the object that we want to capture.</p>
</div>
<div class="section level3">
<h3 id="laser-scanning">Laser scanning<a class="anchor" aria-label="anchor" href="#laser-scanning"></a>
</h3>
<p>Laser scanning refers to all the techniques which deploy a laser to
calculate shape, i.e., the distance between an object and the point from
where the laser is emitted. Laser scanning can also acquire colour
information if it is equipped with sensors to get such data. When
deploying laser scanning, a set of points or point-cloud is acquired.
Each point will have x, y, z coordinates.</p>
<p>The main types of laser scanning are:</p>
<div class="section level4">
<h4 id="time-of-flight-tof">Time of flight (TOF)<a class="anchor" aria-label="anchor" href="#time-of-flight-tof"></a>
</h4>
<p>This is used for terrestrial laser scanning capturing archaeological
or excavation sites, as well as larger architectural monuments. These
scanners essentially measure the time it takes for a laser pulse emitted
from the scanner to reach a given surface and then return. The accuracy
of these scanners depends on the accuracy of their timer when
calculating the returning signal.</p>
<p>TOF systems can also acquire colour through internal or external
cameras attached to the scanner. Usually, TOF systems are deployed for
acquisition up to 300 meters away but might have lower acquisition rates
and accuracy.</p>
</div>
<div class="section level4">
<h4 id="structured-light-scanners">Structured light scanners<a class="anchor" aria-label="anchor" href="#structured-light-scanners"></a>
</h4>
<p>These are scanners which emit patterns of light, such as stripes,
parallel lines and QR-code-like light onto the surface of an object.
Such scanners measure the distance from the scanner to the surface of
the scanned object by monitoring the distortions of the projected
pattern using triangulation.</p>
<p>Structured light scanners, depending on the type of light pattern
they emit, can be divided into phase shift, random speckle and
multi-line scanners. The most popular structured light scanners are the
phase shift scanners, and these are used to acquire objects at
approximately 80 meters away (or more depending on the scanner).</p>
<p>Random speckle and multi-line scanners are mostly used to acquire
assets with handheld scanners at short distances. Structured light
scanners are faster than TOF scanners.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/0/09/Input_image_for_3D_scanner.png" style="width:60.0%" alt="" class="figure mx-auto d-block"><figcaption>A structured-light 3D scanner is a 3D scanning device
for measuring the three-dimensional shape of an object using projected
light patterns and a camera system, Public domain, Hesameh, under CC BY
4.0, via <a href="https://commons.wikimedia.org/wiki/File:Input_image_for_3D_scanner.png" class="external-link">Wikimedia
Commons</a></figcaption></figure>
</div>
<div class="section level4">
<h4 id="triangulation">Triangulation<a class="anchor" aria-label="anchor" href="#triangulation"></a>
</h4>
<p>These scanners work for a shorter-range acquisition, usually up to 2
meters away, and are equipped with a laser source and a camera. Such
scanners use a spot, line or pattern laser beam which is emitted onto an
object and the deformation of such line or pattern is measured by a
camera using the triangulation principle to calculate depth.
Triangulation scanners can be very ‘accurate’ and can also capture
colour depending on the options offered by each model.</p>
</div>
<div class="section level4">
<h4 id="airborne-laser-scanning-or-lidar-light-detection-and-ranging">Airborne laser scanning or LiDAR (light detection and ranging)<a class="anchor" aria-label="anchor" href="#airborne-laser-scanning-or-lidar-light-detection-and-ranging"></a>
</h4>
<p>These are scanners used on aircrafts to acquire 3D information about
the earth’s surface and ‘reveal’ features in the landscape, such as
surface structures, which can be visible as marks on the ground. LiDAR
scanners emit pulses which are reflected when they reach the ground.</p>
<p>The time needed for the laser light to return to the aircraft along
with the information from GPS enables to construct detailed and
‘accurate’ maps of the surface of the ground. The advantage of the LiDAR
systems is that they can filter signals and choose the ones which will
reach the ground instead of the ones which are reflected by woodland and
plants.</p>
<p>In such a way, ‘hidden’ constructions can become visible in places
where access and surveys are difficult to happen. Historic England has
several examples of the deployment of such scanning technology on their
<a href="https://historicengland.org.uk/research/methods/airborne-remote-sensing/lidar/" class="external-link">website</a>
along with examples of LiDAR mapping.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/2/2c/Yellowscan_LIDAR_on_OnyxStar_FOX-C8_HD.jpg" style="width:70.0%" alt="" class="figure mx-auto d-block"><figcaption>LIDAR survey being performed with a Yellowscan LIDAR
on the OnyxStar FOX-C8 HD from AltiGator in November 2015, Belgium,
Public Domain, USGS, under CC BY-SA 4.0, via <a href="https://commons.wikimedia.org/wiki/File:Yellowscan_LIDAR_on_OnyxStar_FOX-C8_HD.jpg" class="external-link">Wikimedia
Commons</a></figcaption></figure>
</div>
</div>
<div class="section level3">
<h3 id="computed-tomography-ct">Computed Tomography (CT)<a class="anchor" aria-label="anchor" href="#computed-tomography-ct"></a>
</h3>
<p>This method comes from the discipline of medicine and is a powerful
non-invasive tool to capture information about the interior of an
object. The way that CT works is by taking sequences of X-rays at 360
degrees around the object. The acquired ‘2D slices’ are then computed to
generate volumetric data.</p>
<p>CT is less accessible for heritage digitisation, due to the high cost
of such equipment, and hence it often requires transferring artefacts to
medical facilities. In the heritage domain, computed tomography has been
used widely to document and study mummies (mostly Egyptian) without
having to unwrap them.</p>
<p>Yet, the deployment of the technology to document mummified bodies
has received criticism from several scholars as well as part of the
public. Further information on this topic can be found in the case study
<a href="https://teach.dariah.eu/mod/lesson/view.php?id=829&amp;pageid=755" class="external-link">Disturbing
the Dead</a> of the #dariahTeach website.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/9/9a/US_Navy_110427-N-2531L-135_Tori_Randall%2C_Ph.D._prepares_a_550-year_old_Peruvian_child_mummy_for_a_CT_scan.jpg" style="width:70.0%" alt="" class="figure mx-auto d-block"><figcaption>SAN DIEGO (April 27, 2011) Tori Randall, Ph.D.,
curator for the Department of Physical Anthropology at the San Diego
Museum of Man, prepares a 550-year-old Peruvian child mummy for a CT
scan at Naval Medical Center San Diego. The medical centre is the only
medical facility in San Diego County with a Flash Dual Source 128 CT
scanner that is Dual Energy capable. This unique capability uses two
different energy sources to differentiate characteristics in tissue and
bone beyond conventional CT imaging. (U.S. Navy photo by Mass
Communication Specialist 3rd Class Samantha A. Lewis/Released), Public
domain, Mass Communication Specialist 3rd Class Samantha A. Lewis under
CC BY 4.0, via <a href="https://commons.wikimedia.org/wiki/File:US_Navy_110427-N-2531L-135_Tori_Randall,_Ph.D._prepares_a_550-year_old_Peruvian_child_mummy_for_a_CT_scan.jpg" class="external-link">Wikimedia
Commons</a></figcaption></figure>
</div>
<div class="section level3">
<h3 id="reflectance-transformation-imaging-rti">Reflectance Transformation Imaging (RTI)<a class="anchor" aria-label="anchor" href="#reflectance-transformation-imaging-rti"></a>
</h3>
<p>Reflectance transformation Imaging refers to the method of capturing
surface and colour for objects which are relatively flat but have a
certain ‘implicit geometry’. These can be anything from engraved tablets
and carved objects to paintings, coins and inscriptions.</p>
<p>RTI was developed in the HP Labs in 2001 and constitutes a method
which mathematically enhances the surface shape and colour of an object
by calculating and visualising the direction of the light which was used
when acquiring images with a camera. RTI is not a 3D digitisation
method, and it could be better described as a qualitative 2.5D
digitisation technique to document material culture.</p>
<p>The most popular RTI method is Highlight RTI which can be done by
using a camera on a tripod, a source of light and other easily found
equipment (ball, measuring tape, backdrop fabric etc). Another method is
the Dome RTI. This needs a dome with attached lights on it and a camera
placed on top to acquire a series of images while dedicated software
controls the lights on the dome. In both cases, the acquired data are
processed with dedicated software to produce a relightable image of the
object from any direction, enabling improved viewing, studying and
enjoyment.</p>
<figure><img src="../fig/IMG_0439.jpg" style="width:70.0%" alt="" class="figure mx-auto d-block"><figcaption>Highlight RTI setup © by the 3D Service Suite,
University of Brighton under CC BY 4.0</figcaption></figure><figure><img src="../fig/cun_tablet.png" style="width:80.0%" alt="" class="figure mx-auto d-block"><figcaption>Visualising the relightable image of a cuneiform
tablet from the Brighton Museum and Art Gallery using the RTI viewer
software © by the 3D Service Suite, University of Brighton under CC BY
4.0</figcaption></figure><p>Lastly, several examples of RTI can be viewed on the <a href="https://vcg.isti.cnr.it/rti/webviewer.php" class="external-link">dedicated website</a>
of the Visual Computing Lab of the CNR- ISTI research institute.</p>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>
</section></section><section id="aio-resources-and-further-reading"><p>Content from <a href="resources-and-further-reading.html">Resources and Further Reading</a></p>
<hr>
<p>Last updated on 2024-02-03 |
        
        <a href="https://github.com/culturedigitalskills/2024-3d-digitisation-methods/edit/main/episodes/resources-and-further-reading.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 0 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<p>Archaeology Data Service. Guides to good practice: 3D models.
Retrieved from: <a href="https://archaeologydataservice.ac.uk/help-guidance/guides-to-good-practice/data-analysis-and-visualisation/3d-models/aims-and-objectives/3d-models-in-archaeology/" class="external-link uri">https://archaeologydataservice.ac.uk/help-guidance/guides-to-good-practice/data-analysis-and-visualisation/3d-models/aims-and-objectives/3d-models-in-archaeology/</a></p>
<p>Barreau, J.-B., Leroy Du Cardonnoy, E., Laroche, F., Madeleine, S.,
Mathieu, V., Granier, X., Mora, P., Pouyet, T., &amp; Chayani, M. (2021,
April 1). Specification Writing Guide : How To Manage a Project in 3D
for Cultural Heritage. HAL Archives Ouvertes. <a href="https://hal.science/hal-03193142" class="external-link uri">https://hal.science/hal-03193142</a></p>
<p>Cultural Heritage Imaging. Overview of CHI technologies. Retrieved
from: <a href="https://culturalheritageimaging.org/Technologies/Overview/" class="external-link uri">https://culturalheritageimaging.org/Technologies/Overview/</a></p>
<p>Digital Preservation Coalition and Artefactual Systems (2021).
Preserving 3D Data Types Series. <a href="http://doi.org/10.7207/twgn21-14" class="external-link uri">http://doi.org/10.7207/twgn21-14</a></p>
<p>European Commission- Expert Group on Digital Cultural Heritage and
Europeana (2020). Basic principles and tips for 3D digitisation of
cultural heritage. Retrieved from: <a href="https://digital-strategy.ec.europa.eu/en/library/basic-principles-and-tips-3d-digitisation-cultural-heritage" class="external-link uri">https://digital-strategy.ec.europa.eu/en/library/basic-principles-and-tips-3d-digitisation-cultural-heritage</a></p>
<p>Gibson A. P. (2023). Medical imaging applied to heritage. The British
journal of radiology, 96(1152), 20230611. <a href="https://doi.org/10.1259/bjr.20230611" class="external-link uri">https://doi.org/10.1259/bjr.20230611</a></p>
<p>Moore, J., Rountrey, A., &amp; Hannah Scates Kettler. (2022). 3D Data
Creation to Curation: Community Standards for 3D Data Preservation.
Assoc. of College &amp; Research Libraries.</p>
<p>Papadopoulos, C. (2020). Course: Remaking Material Culture in 3D.
dariahTeach: Open Educational Resources for the Digital Arts and
Humanities. Retrieved from: <a href="https://teach.dariah.eu/course/view.php?id=55&amp;section=0" class="external-link uri">https://teach.dariah.eu/course/view.php?id=55&amp;section=0</a></p>
<p>Share 3D. Share 3D guidelines. Retrieved from: <a href="https://carare.gitbook.io/share-3d-guidelines/" class="external-link uri">https://carare.gitbook.io/share-3d-guidelines/</a></p>
<p>The London Charter (2009). The London Charter: For the Computer-Based
Visualisation of Cultural Heritage. Retrieved from: <a href="https://londoncharter.org/fileadmin/templates/main/docs/london_charter_2_1_en.pdf" class="external-link uri">https://londoncharter.org/fileadmin/templates/main/docs/london_charter_2_1_en.pdf</a></p></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/culturedigitalskills/2024-3d-digitisation-methods/edit/main/README.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/culturedigitalskills/2024-3d-digitisation-methods/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/culturedigitalskills/2024-3d-digitisation-methods/" class="external-link">Source</a></p>
				<p><a href="https://github.com/culturedigitalskills/2024-3d-digitisation-methods/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:K.Rodriguez@brighton.ac.uk">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.2" class="external-link">sandpaper (0.16.2)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.3" class="external-link">pegboard (0.7.3)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.1" class="external-link">varnish (1.0.1)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://culturedigitalskills.github.io/2024-3d-digitisation-methods/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://culturedigitalskills.github.io/2024-3d-digitisation-methods/instructor/aio.html",
  "identifier": "https://culturedigitalskills.github.io/2024-3d-digitisation-methods/instructor/aio.html",
  "dateCreated": "2024-01-18",
  "dateModified": "2024-02-03",
  "datePublished": "2024-02-03"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code -->
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

